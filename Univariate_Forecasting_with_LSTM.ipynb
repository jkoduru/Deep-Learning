{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariate Forecasting with LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sHsREXiDwlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fce5ac5-be9f-4be6-bf3d-17d1ab97e253"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,Dense,Bidirectional"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BTbQppCbsDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sample Univariate sequence\n",
        "seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IouysEI1Yli",
        "colab_type": "text"
      },
      "source": [
        "Supervised Algorightms require the data in the form of input(X) and output(y).\n",
        "We can write a function to transform a given sequence into input and output "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjlFbFdpicYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = [],[]\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence)-1:\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X),np.array(y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clCxCH5Ui98-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps=3\n",
        "X, y = split_sequence(seq,n_steps)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HN8LV4cFSTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5e7b2fa4-89c3-4fd1-f78a-770cef3969ba"
      },
      "source": [
        "for i in range(len(X)):\n",
        "  print(X[i],y[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3] 4\n",
            "[2 3 4] 5\n",
            "[3 4 5] 6\n",
            "[4 5 6] 7\n",
            "[5 6 7] 8\n",
            "[6 7 8] 9\n",
            "[7 8 9] 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCJGA2lIHr6",
        "colab_type": "text"
      },
      "source": [
        "**1. LSTM**\n",
        "\n",
        "The input to LSTM layer must be three-dimensional\n",
        "\n",
        "*   Samples\n",
        "*   Timesteps\n",
        "*   Fetures\n",
        "\n",
        "When defining the input layer of your LSTM network, the network assumes you have one or more samples and requires that you specify the number of time steps and the number of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rYwAZBKLEqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape the input data into 3D shape as required by LSTM\n",
        "n_features = 1\n",
        "X= X.reshape(X.shape[0],X.shape[1],n_features)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbhOq7NGc0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define LSTM Model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(n_steps,n_features)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q9R8cFDGcxT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f7b1794-8510-4f25-ba9f-7153ce5c86a5"
      },
      "source": [
        "#Fit Model\n",
        "model.fit(X,y,epochs=200,verbose=0)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4294c4d5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-mH3XpfGct9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a4406d1-39c7-4c67-ef00-9aa1fa4e98a3"
      },
      "source": [
        "#Prediction\n",
        "x_test = np.array([[7,8,9]])\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],n_features)\n",
        "y_hat = model.predict(x_test)\n",
        "print(y_hat)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.917564]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVvGkWm4RTOX",
        "colab_type": "text"
      },
      "source": [
        "**Stacked LSTM model**\n",
        "\n",
        "LSTMs produce 2D output as an interpretation from end of the sequence. We can change this by LSTM output a value for each timestep in the input data by setting Return Sequence =True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jPNL-gBQiFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create LSTM Stacked model\n",
        "stack_model = Sequential()\n",
        "stack_model.add(LSTM(50,activation='relu',return_sequences=True, input_shape=(n_steps,n_features)))\n",
        "stack_model.add(LSTM(50,activation='relu'))\n",
        "stack_model.add(Dense(1))\n",
        "stack_model.compile(optimizer='adam',loss='mse')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_QIt1CqSMyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "761fe1fd-9e8c-4b7b-f4ea-315bdd9e31dc"
      },
      "source": [
        "#Fit model\n",
        "stack_model.fit(X,y,epochs=200, verbose=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4294c4d780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vtGoSBASMuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76377017-d0d3-4d05-b650-8c69cafcdf9a"
      },
      "source": [
        "y_hat_stack = stack_model.predict(x_test)\n",
        "print(y_hat_stack)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.788965]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH67htvUVnNw",
        "colab_type": "text"
      },
      "source": [
        "**Bidirectional LSTM**\n",
        "\n",
        "In some sequence prediction problems, it is benificial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuBGJ1DxWIVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define Bidirectional LSTM Model\n",
        "bidi_model = Sequential()\n",
        "bidi_model.add(Bidirectional(LSTM(50, activation='relu'),input_shape=(n_steps,n_features)))\n",
        "bidi_model.add(Dense(1))\n",
        "bidi_model.compile(optimizer='adam',loss='mse')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KprH3RfVZCun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da77d842-5158-4f2f-a456-2947615e3499"
      },
      "source": [
        "bidi_model.fit(X,y,epochs=200,verbose=0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4294c4d390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDocJKP2YDlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "087ddc37-63f5-471f-9c10-13b060a3bfce"
      },
      "source": [
        "bidi_model.predict(x_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.742871]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}